import streamlit as st
from ui.sidebar import sidebar
from ui.chat_interface import file_upload_screen, processing_screen, chat_screen
from core.document_processor import process_uploaded_files
from core.embedding_handler import (
    get_embedding_model, 
    get_or_create_vector_store, 
    generate_session_id,
    recreate_retriever_from_saved
)
from core.llm_handler import get_llm_instance, get_qa_retrieval_chain, get_reranker
from core.chat_history import save_chat_history, load_chat_history, list_chat_sessions
from config import CHAT_HISTORIES_DIR, VECTOR_STORES_DIR
import os
import shutil
import uuid
import json
from datetime import datetime
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document

st.set_page_config(page_title="Chatbot T√†i Li·ªáu RAG", layout="wide")

# Th√™m h√†m tr·ª±c ti·∫øp t√¨m ki·∫øm t√†i li·ªáu khi retriever th·∫•t b·∫°i
def direct_vector_search(question, embedding_model, vs_id, top_k=10):
    """
    T√¨m ki·∫øm tr·ª±c ti·∫øp t·ª´ vector store khi retriever th√¥ng th∆∞·ªùng th·∫•t b·∫°i.
    Tr·∫£ v·ªÅ list c√°c Document.
    """
    if not embedding_model or not vs_id:
        print("[app] Kh√¥ng th·ªÉ th·ª±c hi·ªán t√¨m ki·∫øm tr·ª±c ti·∫øp - thi·∫øu model ho·∫∑c vector store ID")
        return []
    
    try:
        # T√¨m ƒë∆∞·ªùng d·∫´n ƒë·∫øn vector store
        vs_path = os.path.join(VECTOR_STORES_DIR, vs_id)
        if not os.path.exists(vs_path):
            print(f"[app] Kh√¥ng t√¨m th·∫•y vector store t·∫°i {vs_path}")
            return []
            
        # T·∫£i FAISS vector store tr·ª±c ti·∫øp
        try:
            print(f"[app] ƒêang t·∫£i FAISS vector store t·ª´ {vs_path}...")
            vector_store = FAISS.load_local(vs_path, embedding_model, allow_dangerous_deserialization=True)
            
            # Th·ª±c hi·ªán t√¨m ki·∫øm
            print(f"[app] Th·ª±c hi·ªán t√¨m ki·∫øm tr·ª±c ti·∫øp v·ªõi k={top_k}...")
            docs_with_score = vector_store.similarity_search_with_score(question, k=top_k)
            
            # L·ªçc k·∫øt qu·∫£ c√≥ ƒëi·ªÉm s·ªë t·ªët
            docs = [doc for doc, score in docs_with_score]
            print(f"[app] T√¨m th·∫•y {len(docs)} k·∫øt qu·∫£ trong t√¨m ki·∫øm tr·ª±c ti·∫øp")
            
            # Th√™m th√¥ng tin v√†o metadata
            for doc in docs:
                doc.metadata["direct_search"] = True
                
            return docs
            
        except Exception as e:
            print(f"[app] L·ªói khi t·∫£i vector store: {e}")
            return []
    except Exception as e:
        print(f"[app] L·ªói trong direct_vector_search: {e}")
        return []

def local_css(file_name):
    with open(file_name, encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

local_css("style.css")

# --- Sidebar ---
with st.sidebar:
    new_chat, selected_session_id = sidebar()

# --- Session State ---
def reset_to_upload():
    keys_to_reset = [
        "uploaded_files", "vector_store", "retriever", "session_id", 
        "file_names", "messages", "current_session_display_name"
    ]
    for key in keys_to_reset:
        st.session_state[key] = None
    st.session_state.state = "upload"
    st.session_state.processing = False
    st.session_state.bot_answering = False
    st.session_state.messages = [] # ƒê·∫£m b·∫£o messages l√† list r·ªóng
    clear_memory() # G·ªçi h√†m m·ªõi ƒë·ªÉ gi·∫£i ph√≥ng b·ªô nh·ªõ

# H√†m m·ªõi ƒë·ªÉ gi·∫£i ph√≥ng b·ªô nh·ªõ
def clear_memory():
    """Gi·∫£i ph√≥ng b·ªô nh·ªõ b·∫±ng c√°ch x√≥a c√°c ƒë·ªëi t∆∞·ª£ng l·ªõn kh·ªèi session_state"""
    import gc
    
    # H·ªßy b·ªè c√°c ƒë·ªëi t∆∞·ª£ng l·ªõn
    if "retriever" in st.session_state:
        st.session_state.retriever = None
    if "vector_store" in st.session_state:
        st.session_state.vector_store = None
        
    # Bu·ªôc garbage collector thu h·ªìi b·ªô nh·ªõ
    gc.collect()
    print("[app] ƒê√£ gi·∫£i ph√≥ng b·ªô nh·ªõ kh√¥ng c·∫ßn thi·∫øt")

# Kh·ªüi t·∫°o session_state n·∫øu ch∆∞a c√≥
default_states = {
    "state": "upload",
    "uploaded_files": None,
    "processing": False,
    "vector_store": None,
    "retriever": None,  # Th√™m tr∆∞·ªùng m·ªõi cho retriever n√¢ng cao
    "session_id": None,
    "file_names": None,
    "messages": [],
    "bot_answering": False,
    "current_session_display_name": None,
    "stop_action_requested": False
}
for key, value in default_states.items():
    if key not in st.session_state:
        st.session_state[key] = value

# --- X·ª≠ l√Ω New Chat ho·∫∑c ch·ªçn chat c≈© ---
if new_chat:
    reset_to_upload()
    st.rerun()

if selected_session_id:
    if st.session_state.session_id != selected_session_id or st.session_state.state != "chatting":
        st.session_state.session_id = selected_session_id
        messages, display_name = load_chat_history(selected_session_id)
        st.session_state.messages = messages
        st.session_state.current_session_display_name = display_name
        
        embedding_model = get_embedding_model()
        if embedding_model:
            # S·ª≠ d·ª•ng h√†m m·ªõi ƒë·ªÉ t√°i t·∫°o retriever t·ª´ d·ªØ li·ªáu ƒë√£ l∆∞u
            retriever = recreate_retriever_from_saved(selected_session_id, embedding_model)
            if retriever:
                st.session_state.retriever = retriever
                st.session_state.vector_store = None  # Kh√¥ng c·∫ßn l∆∞u vector_store ri√™ng
                st.session_state.file_names = None 
                st.session_state.state = "chatting"
                st.session_state.processing = False # ƒê·∫£m b·∫£o reset processing flag
                st.session_state.bot_answering = False # ƒê·∫£m b·∫£o reset bot_answering flag
            else:
                st.error(f"Kh√¥ng th·ªÉ t·∫£i c∆° s·ªü tri th·ª©c cho session '{st.session_state.current_session_display_name}'. C√≥ th·ªÉ ƒë√£ b·ªã x√≥a ho·∫∑c l·ªói. Vui l√≤ng t·∫°o chat m·ªõi.")
                reset_to_upload() 
        else:
            st.error("L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ kh·ªüi t·∫°o embedding model khi t·∫£i session.")
            reset_to_upload()
    st.rerun()

# --- Giao di·ªán ch√≠nh ---
if st.session_state.state == "upload":
    st.title("üí¨ Chatbot H·ªèi ƒê√°p T√†i Li·ªáu (RAG v·ªõi Llama 3)")
    st.markdown("#### T·∫£i l√™n t√†i li·ªáu c·ªßa b·∫°n ƒë·ªÉ b·∫Øt ƒë·∫ßu")
    valid_files, error_files, start_clicked, _ = file_upload_screen(st.session_state.uploaded_files)
    if valid_files:
        st.session_state.uploaded_files = valid_files
    else:
        st.session_state.uploaded_files = None
    
    if error_files:
        st.warning("M·ªôt s·ªë file kh√¥ng h·ª£p l·ªá v√† s·∫Ω b·ªã b·ªè qua:")
        for fname, reason in error_files.items():
            st.write(f"- {fname}: {reason}")

    if start_clicked and st.session_state.uploaded_files:
        # T·∫°o session_id m·ªõi cho chat m·ªõi
        new_session_id = generate_session_id([f.name for f in st.session_state.uploaded_files])
        st.session_state.session_id = new_session_id
        # ƒê·∫∑t display_name ban ƒë·∫ßu b·∫±ng session_id (ho·∫∑c c√≥ th·ªÉ t√πy ch·ªânh sau)
        st.session_state.current_session_display_name = new_session_id 
        st.session_state.file_names = [f.name for f in st.session_state.uploaded_files] # L∆∞u t√™n file
        st.session_state.state = "processing"
        st.session_state.stop_action_requested = False # Reset c·ªù d·ª´ng khi b·∫Øt ƒë·∫ßu x·ª≠ l√Ω m·ªõi
        st.session_state.bot_answering = False # ƒê·∫£m b·∫£o bot_answering l√† false
        st.rerun()

elif st.session_state.state == "processing":
    st.title(f"‚öôÔ∏è ƒêang x·ª≠ l√Ω: {st.session_state.current_session_display_name}")
    if not st.session_state.uploaded_files:
        st.warning("Kh√¥ng c√≥ file n√†o ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng quay l·∫°i v√† t·∫£i l√™n.")
        if st.button("Quay l·∫°i trang Upload"):
            reset_to_upload()
            st.rerun()
    else:
        stop_processing_clicked = processing_screen(st.session_state.uploaded_files)
        if stop_processing_clicked:
            st.warning("ƒê√£ d·ª´ng qu√° tr√¨nh x·ª≠ l√Ω t√†i li·ªáu.")
            reset_to_upload() # reset_to_upload ƒë√£ bao g·ªìm vi·ªác x√≥a session_id, etc.
            st.rerun()
        else:
            if not st.session_state.vector_store and not st.session_state.retriever:  # Ch·ªâ x·ª≠ l√Ω n·∫øu ch∆∞a c√≥ vector_store ho·∫∑c retriever
                parent_chunks, child_chunks = process_uploaded_files(st.session_state.uploaded_files)
                
                if parent_chunks and child_chunks:
                    embedding_model = get_embedding_model()
                    if embedding_model:
                        # Truy·ªÅn c·∫£ parent_chunks v√† child_chunks ƒë·ªÉ x·ª≠ l√Ω n√¢ng cao
                        retriever, vs_id_saved = get_or_create_vector_store(
                            st.session_state.session_id, 
                            (parent_chunks, child_chunks),  # Truy·ªÅn tuple g·ªìm c·∫£ parent v√† child chunks
                            embedding_model
                        )
                        
                        if retriever:
                            # L∆∞u l·∫°i retriever v√† chuy·ªÉn th√†nh main retriever ƒë·ªÉ d√πng sau n√†y
                            st.session_state.retriever = retriever
                            
                            # C√≥ th·ªÉ c≈©ng l∆∞u vector_store n·∫øu c·∫ßn thi·∫øt
                            # st.session_state.vector_store = vector_store
                            
                            # Kh·ªüi t·∫°o tin nh·∫Øn ch√†o m·ª´ng ƒë·∫ßu ti√™n
                            st.session_state.messages = [{"role": "assistant", "content": f"T√†i li·ªáu cho '{st.session_state.current_session_display_name}' ƒë√£ s·∫µn s√†ng! B·∫°n h√£y ƒë·∫∑t c√¢u h·ªèi."}]
                            save_chat_history(
                                st.session_state.session_id, 
                                st.session_state.messages, 
                                display_name_to_set=st.session_state.current_session_display_name
                            )
                            st.session_state.state = "chatting" # Chuy·ªÉn sang chatting
                            st.session_state.processing = False
                            st.session_state.bot_answering = False
                            st.session_state.stop_action_requested = False # ƒê·∫£m b·∫£o reset c·ªù d·ª´ng
                            st.rerun()
                        else:
                            st.error("Kh√¥ng th·ªÉ t·∫°o c∆° s·ªü tri th·ª©c.")
                            reset_to_upload()
                            st.rerun()
                    else:
                        st.error("L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ kh·ªüi t·∫°o embedding model khi x·ª≠ l√Ω t√†i li·ªáu.")
                        reset_to_upload()
                        st.rerun()
                else:
                    st.error("Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c t√†i li·ªáu. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file v√† th·ª≠ l·∫°i.")
                    # Kh√¥ng reset_to_upload() ngay, cho ph√©p ng∆∞·ªùi d√πng th·∫•y l·ªói v√† c√≥ th·ªÉ quay l·∫°i
                    if st.button("Th·ª≠ l·∫°i v·ªõi file kh√°c"):
                        reset_to_upload()
                        st.rerun()

elif st.session_state.state == "chatting":
    if not st.session_state.session_id or not st.session_state.current_session_display_name:
        st.warning("Kh√¥ng c√≥ session n√†o ƒë∆∞·ª£c ch·ªçn ho·∫∑c session b·ªã l·ªói. Vui l√≤ng t·∫°o chat m·ªõi ho·∫∑c ch·ªçn t·ª´ l·ªãch s·ª≠.")
        if st.button("B·∫Øt ƒë·∫ßu Chat M·ªõi"):
            reset_to_upload()
            st.rerun()
        st.stop()

    st.title(f"üí¨ {st.session_state.current_session_display_name}")

    # Khu v·ª±c qu·∫£n l√Ω session (ƒë·ªïi t√™n, x√≥a)
    with st.expander("T√πy ch·ªçn Session", expanded=False):
        new_name = st.text_input(
            "ƒê·ªïi t√™n Session:", 
            value=st.session_state.current_session_display_name,
            key=f"rename_input_{st.session_state.session_id}"
        )
        if st.button("L∆∞u t√™n m·ªõi", key=f"save_rename_btn_{st.session_state.session_id}"):
            if new_name.strip() and new_name.strip() != st.session_state.current_session_display_name:
                save_chat_history(
                    st.session_state.session_id, 
                    st.session_state.messages, 
                    display_name_to_set=new_name.strip()
                )
                st.session_state.current_session_display_name = new_name.strip()
                st.success(f"ƒê√£ ƒë·ªïi t√™n session th√†nh: {new_name.strip()}")
                st.rerun()
            elif not new_name.strip():
                st.warning("T√™n hi·ªÉn th·ªã kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.")
            else:
                st.info("T√™n m·ªõi gi·ªëng v·ªõi t√™n hi·ªán t·∫°i.")

        st.markdown("---")
        st.markdown("<h5 style='color: red;'>X√≥a Session n√†y</h5>", unsafe_allow_html=True)
        confirm_delete_text = f"T√¥i ch·∫Øc ch·∫Øn mu·ªën x√≥a session '{st.session_state.current_session_display_name}' v√† t·∫•t c·∫£ d·ªØ li·ªáu li√™n quan."
        confirm_delete = st.checkbox(confirm_delete_text, key=f"confirm_delete_cb_{st.session_state.session_id}")
        
        if st.button("X√ÅC NH·∫¨N X√ìA", type="primary", disabled=not confirm_delete, key=f"confirm_delete_btn_{st.session_state.session_id}"):
            if confirm_delete:
                session_id_to_delete = st.session_state.session_id
                display_name_deleted = st.session_state.current_session_display_name
                
                history_file_path = os.path.join(CHAT_HISTORIES_DIR, f"{session_id_to_delete}.json")
                vector_store_path = os.path.join(VECTOR_STORES_DIR, session_id_to_delete)
                
                deleted_files = False
                try:
                    if os.path.exists(history_file_path):
                        os.remove(history_file_path)
                        deleted_files = True
                    if os.path.exists(vector_store_path):
                        shutil.rmtree(vector_store_path)
                        deleted_files = True
                    
                    if deleted_files:
                        st.success(f"ƒê√£ x√≥a th√†nh c√¥ng session: {display_name_deleted} (ID: {session_id_to_delete})")
                    else:
                        st.warning(f"Kh√¥ng t√¨m th·∫•y file n√†o ƒë·ªÉ x√≥a cho session: {display_name_deleted}. C√≥ th·ªÉ ƒë√£ ƒë∆∞·ª£c x√≥a tr∆∞·ªõc ƒë√≥.")
                    
                    reset_to_upload()
                    st.rerun()
                except Exception as e:
                    st.error(f"L·ªói khi x√≥a session '{display_name_deleted}': {e}")
            else:
                st.warning("Vui l√≤ng x√°c nh·∫≠n tr∆∞·ªõc khi x√≥a.")

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat v√† placeholder cho "Bot ƒëang suy nghƒ©..."
    st.markdown("<div class='chat-history-area'>", unsafe_allow_html=True)
    for idx, message in enumerate(st.session_state.messages):
        # ƒê·∫£m b·∫£o tin nh·∫Øn ch√†o m·ª´ng ƒë·∫ßu ti√™n c√≥ sources
        if idx == 0 and message["role"] == "assistant" and "sources" not in message:
            message["sources"] = [{
                "source": "Tin nh·∫Øn ƒë·∫ßu ti√™n",
                "chunk_id": "initial-message",
                "content": "ƒê√¢y l√† tin nh·∫Øn ch√†o m·ª´ng, kh√¥ng c√≥ ngu·ªìn tham kh·∫£o c·ª• th·ªÉ."
            }]
                
        # Debug print cho m·ªói message
        print(f"\n=== DEBUG MESSAGE {idx} ===")
        print(f"Role: {message.get('role')}")
        print(f"Has sources: {'sources' in message}")
        if 'sources' in message:
            print(f"Sources length: {len(message['sources'])}")
            if len(message['sources']) > 0:
                print(f"First source: {message['sources'][0]}")
        print(f"=== END DEBUG MESSAGE {idx} ===\n")
        
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Debug print ƒë·ªÉ ki·ªÉm tra message
            print(f"\n=== DEBUG UI MESSAGE ===")
            print(f"Message role: {message.get('role')}")
            print(f"Message keys: {message.keys()}")
            print(f"'sources' in message: {'sources' in message}")
            if 'sources' in message:
                print(f"message['sources'] type: {type(message['sources'])}")
                print(f"message['sources'] length: {len(message['sources']) if message['sources'] else 0}")
                print(f"message['sources'] is empty or None: {not message['sources']}")
            print(f"=== END DEBUG UI MESSAGE ===\n")
            
            # Lu√¥n hi·ªÉn th·ªã ph·∫ßn ngu·ªìn cho tin nh·∫Øn c·ªßa assistant
            if message["role"] == "assistant":
                st.markdown("**NGU·ªíN THAM KH·∫¢O:**")
                
                # ƒê·∫£m b·∫£o lu√¥n c√≥ ngu·ªìn, th√™m n·∫øu kh√¥ng c√≥
                if "sources" not in message or message["sources"] is None:
                    message["sources"] = [{
                        "source": "Tin nh·∫Øn h·ªá th·ªëng",
                        "chunk_id": "system-message",
                        "content": "Kh√¥ng c√≥ ngu·ªìn tham kh·∫£o c·ª• th·ªÉ cho tin nh·∫Øn n√†y."
                    }]
                    
                elif not message["sources"] or len(message["sources"]) == 0:
                    message["sources"] = [{
                        "source": "K·∫øt qu·∫£ t√¨m ki·∫øm",
                        "chunk_id": "auto-generated",
                        "content": "H·ªá th·ªëng kh√¥ng t√¨m th·∫•y ngu·ªìn tham kh·∫£o c·ª• th·ªÉ cho c√¢u h·ªèi n√†y. C√¢u tr·∫£ l·ªùi ƒë∆∞·ª£c t·ªïng h·ª£p t·ª´ ki·∫øn th·ª©c c√≥ s·∫µn."
                    }]
                
                # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ s·ªë l∆∞·ª£ng ngu·ªìn
                st.info(f"C√≥ {len(message['sources'])} ngu·ªìn ƒë∆∞·ª£c t√¨m th·∫•y.")
                
                # Hi·ªÉn th·ªã c√°c ngu·ªìn
                    for i, source in enumerate(message["sources"]):
                    try:
                        source_name = source.get('source', 'N/A')
                        chunk_id = source.get('chunk_id', 'N/A')
                        content = source.get('content', 'N/A')
                        
                        st.markdown(f"**Ngu·ªìn {i+1}:** {source_name} - Chunk ID: {chunk_id}")
                        st.code(content[:150] + "..." if len(content) > 150 else content)
                    except Exception as e:
                        st.error(f"L·ªói khi hi·ªÉn th·ªã ngu·ªìn #{i+1}: {e}")
                        st.text(f"D·ªØ li·ªáu ngu·ªìn: {source}")

    # Simplified: Display "Bot ƒëang suy nghƒ©..." directly if bot is answering
    if st.session_state.bot_answering:
        with st.chat_message("assistant"):
            st.markdown("‚ñå Bot ƒëang suy nghƒ©...")
        
    st.markdown("</div>", unsafe_allow_html=True) # ƒê√≥ng div chat-history-area

    # G·ªçi chat_screen ƒë·ªÉ l·∫•y input v√† c√°c n√∫t ƒëi·ªÅu khi·ªÉn
    prompt, send_triggered, stop_button_clicked_in_ui = chat_screen(
        st.session_state.messages, 
        st.session_state.bot_answering
    )

    # ∆Øu ti√™n x·ª≠ l√Ω y√™u c·∫ßu d·ª´ng n·∫øu c√≥
    if st.session_state.get('stop_action_requested', False):
        if st.session_state.bot_answering: 
            st.session_state.bot_answering = False
            # Placeholder s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông x√≥a ·ªü l·∫ßn rerun ti·∫øp theo b·ªüi kh·ªëi logic ·ªü tr√™n
            # (khi bot_answering l√† False v√† placeholder t·ªìn t·∫°i)
            
            if not st.session_state.messages or st.session_state.messages[-1]["content"] != ":warning: Tr·∫£ l·ªùi ƒë√£ b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng.":
                st.session_state.messages.append({"role": "assistant", "content": ":warning: Tr·∫£ l·ªùi ƒë√£ b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng."})
                save_chat_history(st.session_state.session_id, st.session_state.messages, st.session_state.current_session_display_name)
            
            st.session_state.stop_action_requested = False 
            st.rerun()
        else:
            st.session_state.stop_action_requested = False
            # Kh√¥ng c·∫ßn rerun n·∫øu kh√¥ng c√≥ g√¨ thay ƒë·ªïi

    elif send_triggered and not st.session_state.bot_answering and prompt.strip():
        st.session_state.messages.append({"role": "user", "content": prompt.strip()})
        st.session_state.bot_answering = True
        st.session_state.stop_action_requested = False 
        save_chat_history(st.session_state.session_id, st.session_state.messages, st.session_state.current_session_display_name)
        # Placeholder s·∫Ω ƒë∆∞·ª£c t·∫°o ·ªü l·∫ßn rerun ti·∫øp theo b·ªüi kh·ªëi logic ·ªü tr√™n
        st.rerun()

    elif st.session_state.bot_answering:
        # Placeholder ƒë√£ ƒë∆∞·ª£c hi·ªÉn th·ªã b·ªüi kh·ªëi logic ·ªü tr√™n tr∆∞·ªõc khi chat_screen ƒë∆∞·ª£c g·ªçi.
        # Gi·ªù ch·ªâ t·∫≠p trung v√†o vi·ªác l·∫•y c√¢u tr·∫£ l·ªùi.

        if not st.session_state.retriever and not st.session_state.vector_store:
            st.warning("ƒêang th·ª≠ t·∫£i l·∫°i c∆° s·ªü tri th·ª©c...")
            embedding_model = get_embedding_model()
            if embedding_model:
                # S·ª≠ d·ª•ng h√†m m·ªõi ƒë·ªÉ t√°i t·∫°o retriever t·ª´ d·ªØ li·ªáu ƒë√£ l∆∞u
                retriever = recreate_retriever_from_saved(st.session_state.session_id, embedding_model)
                if retriever:
                    st.session_state.retriever = retriever
                    st.rerun() 
                else:
                    st.error("L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ t·∫£i c∆° s·ªü tri th·ª©c cho phi√™n l√†m vi·ªác n√†y. Vui l√≤ng th·ª≠ t·∫°o phi√™n m·ªõi t·ª´ ƒë·∫ßu.")
                    st.session_state.bot_answering = False # D·ª´ng bot n·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c VS
                    # Placeholder s·∫Ω t·ª± ƒë·ªông x√≥a ·ªü rerun ti·∫øp theo
                    reset_to_upload()
                    st.rerun()
            else:
                st.error("L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ kh·ªüi t·∫°o embedding model ƒë·ªÉ t·∫£i l·∫°i vector store.")
                st.session_state.bot_answering = False # D·ª´ng bot
                reset_to_upload()
                st.rerun()

        # ∆Øu ti√™n s·ª≠ d·ª•ng retriever n√¢ng cao (ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o v·ªõi parent-child)
        retriever_to_use = st.session_state.retriever
            
        llm = get_llm_instance()
        qa_chain = get_qa_retrieval_chain(llm, retriever_to_use)
            
            response_content = ""
            sources_list = []
            try:
                last_user_msg_content = ""
                for msg in reversed(st.session_state.messages):
                    if msg["role"] == "user":
                        last_user_msg_content = msg["content"]
                        break
                
                if not last_user_msg_content:
                    st.warning("Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng ƒë·ªÉ x·ª≠ l√Ω.")
                    st.session_state.bot_answering = False
                    st.session_state.stop_action_requested = False 
                    # Placeholder s·∫Ω t·ª± ƒë·ªông x√≥a ·ªü rerun ti·∫øp theo
                    st.rerun()
                else:
                # C·∫≠p nh·∫≠t: S·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c m·ªõi ƒë·ªÉ g·ªçi qa_chain
                try:
                    # Th·ª≠ s·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c invoke c·ªßa LangChain m·ªõi
                    from langchain_core.runnables.config import RunnableConfig
                    response = qa_chain.invoke(
                        {"query": last_user_msg_content},
                        config=RunnableConfig(run_name="QA Query")
                    )
                except Exception as e1:
                    print(f"[app] L·ªói khi s·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c invoke: {e1}")
                    # Fallback sang ph∆∞∆°ng th·ª©c c≈© n·∫øu c·∫ßn
                    try:
                        response = qa_chain({"query": last_user_msg_content})
                    except Exception as e2:
                        print(f"[app] L·ªói nghi√™m tr·ªçng c·∫£ hai ph∆∞∆°ng th·ª©c: {e2}")
                        response = {
                            "result": f"C√≥ l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e2)}",
                            "source_documents": []
                        }
                
                # Debug print ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu tr·∫£ v·ªÅ t·ª´ QA chain
                print("\n\n=== DEBUG QA RESPONSE ===")
                print(f"Response type: {type(response)}")
                print(f"Response keys: {response.keys() if isinstance(response, dict) else 'Not a dict'}")
                print(f"Has source_documents: {'source_documents' in response if isinstance(response, dict) else False}")
                if isinstance(response, dict) and 'source_documents' in response:
                    print(f"Number of source documents: {len(response['source_documents'])}")
                    for i, doc in enumerate(response['source_documents']):
                        print(f"Document {i+1}:")
                        print(f"  Type: {type(doc)}")
                        print(f"  Metadata: {doc.metadata}")
                        print(f"  Page content length: {len(doc.page_content)}")
                        print(f"  Content preview: {doc.page_content[:50]}...")
                print("=== END DEBUG QA RESPONSE ===\n\n")
                
                # Tr√≠ch xu·∫•t k·∫øt qu·∫£ t·ª´ QA chain
                if isinstance(response, dict):
                    response_content = response.get("result", "")
                    raw_sources = response.get("source_documents", [])
                    
                    # Lu√¥n ƒë·∫£m b·∫£o c√≥ √≠t nh·∫•t m·ªôt ngu·ªìn ƒë·ªÉ hi·ªÉn th·ªã
                    sources_list = []
                    if not raw_sources or len(raw_sources) == 0:
                        print("[app] Warning: source_documents r·ªóng, th·ª≠ t√¨m ki·∫øm tr·ª±c ti·∫øp...")
                        
                        # S·ª≠ d·ª•ng t√¨m ki·∫øm tr·ª±c ti·∫øp n·∫øu kh√¥ng c√≥ k·∫øt qu·∫£ t·ª´ retriever
                        embedding_model = get_embedding_model()
                        if embedding_model and st.session_state.session_id:
                            direct_sources = direct_vector_search(last_user_msg_content, embedding_model, st.session_state.session_id, top_k=10)
                            
                            if direct_sources and len(direct_sources) > 0:
                                print(f"[app] T√¨m th·∫•y {len(direct_sources)} ngu·ªìn t·ª´ t√¨m ki·∫øm tr·ª±c ti·∫øp")
                                raw_sources = direct_sources
                                # X·ª≠ l√Ω c√°c ngu·ªìn t√¨m th·∫•y
                                for src in raw_sources:
                                    try:
                                        source_item = {
                                            "source": src.metadata.get("source", "T√¨m ki·∫øm tr·ª±c ti·∫øp") if hasattr(src, "metadata") else "T√¨m ki·∫øm tr·ª±c ti·∫øp",
                                            "chunk_id": src.metadata.get("chunk_id", "direct-search") if hasattr(src, "metadata") else "direct-search",
                                            "content": src.page_content.replace("\\n", " ") if hasattr(src, "page_content") else "No content"
                                        }
                                        sources_list.append(source_item)
                                        print(f"[app] ƒê√£ th√™m ngu·ªìn tr·ª±c ti·∫øp: {source_item['source']}")
                                    except Exception as e:
                                        print(f"[app] L·ªói khi x·ª≠ l√Ω ngu·ªìn tr·ª±c ti·∫øp: {e}")
                        
                        # N·∫øu v·∫´n kh√¥ng c√≥ ngu·ªìn n√†o, t·∫°o ngu·ªìn m·∫∑c ƒë·ªãnh
                        if not sources_list:
                            print("[app] Kh√¥ng th·ªÉ t√¨m th·∫•y ngu·ªìn, t·∫°o ngu·ªìn m·∫∑c ƒë·ªãnh")
                            sources_list = [{
                                "source": "K·∫øt qu·∫£ t·ªïng h·ª£p",
                                "chunk_id": "generated",
                                "content": "Kh√¥ng t√¨m th·∫•y ngu·ªìn tham kh·∫£o c·ª• th·ªÉ. C√¢u tr·∫£ l·ªùi ƒë∆∞·ª£c t·ªïng h·ª£p t·ª´ ki·∫øn th·ª©c chung."
                            }]
                    else:
                        # X·ª≠ l√Ω ngu·ªìn th∆∞·ªùng
                        for src in raw_sources:
                            try:
                                source_item = {
                                    "source": src.metadata.get("source", "N/A") if hasattr(src, "metadata") else "Unknown",
                                    "chunk_id": src.metadata.get("chunk_id", "N/A") if hasattr(src, "metadata") else "unknown",
                                    "content": src.page_content.replace("\\n", " ") if hasattr(src, "page_content") else "No content"
                                }
                                sources_list.append(source_item)
                                print(f"[app] ƒê√£ th√™m ngu·ªìn: {source_item['source']}")
                            except Exception as e:
                                print(f"[app] L·ªói khi x·ª≠ l√Ω ngu·ªìn: {e}")
                                # Th√™m ngu·ªìn l·ªói ƒë·ªÉ c√≥ th√¥ng tin debug
                        sources_list.append({
                                    "source": "L·ªói khi x·ª≠ l√Ω",
                                    "chunk_id": "error",
                                    "content": f"ƒê√£ x·∫£y ra l·ªói: {str(e)}"
                                })
                    
                    # ƒê·∫£m b·∫£o lu√¥n c√≥ √≠t nh·∫•t m·ªôt ngu·ªìn
                    if not sources_list:
                        sources_list = [{
                            "source": "Kh√¥ng c√≥ ngu·ªìn",
                            "chunk_id": "empty",
                            "content": "Kh√¥ng th·ªÉ l·∫•y th√¥ng tin ngu·ªìn t·ª´ c√¢u tr·∫£ l·ªùi."
                        }]
                    
                    # Debug print ƒë·ªÉ ki·ªÉm tra sources_list
                    print("\n\n=== DEBUG SOURCES LIST ===")
                    print(f"Number of sources after conversion: {len(sources_list)}")
                    if len(sources_list) > 0:
                        print(f"First source: {sources_list[0]}")
                    print("=== END DEBUG SOURCES LIST ===\n\n")
                else:
                    # Ph√≤ng tr∆∞·ªùng h·ª£p kh√¥ng ph·∫£i dict
                    response_content = str(response)
                    sources_list = [{
                        "source": "L·ªói ƒë·ªãnh d·∫°ng",
                        "chunk_id": "format-error",
                        "content": "K·∫øt qu·∫£ tr·∫£ v·ªÅ kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n."
                    }]
            except Exception as e:
                response_content = f"ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu: {e}"
            
        # Debug print ƒë·ªÉ ki·ªÉm tra message tr∆∞·ªõc khi th√™m v√†o st.session_state.messages
        print("\n\n=== DEBUG FINAL MESSAGE ===")
        print(f"Response content length: {len(response_content)}")
        print(f"Sources list length: {len(sources_list)}")
        message_to_append = {"role": "assistant", "content": response_content, "sources": sources_list}
        print(f"Message to append has sources: {'sources' in message_to_append}")
        print(f"Message sources length: {len(message_to_append['sources'])}")
        print("=== END DEBUG FINAL MESSAGE ===\n\n")
        
        st.session_state.messages.append(message_to_append)
            save_chat_history(st.session_state.session_id, st.session_state.messages, st.session_state.current_session_display_name)
            st.session_state.bot_answering = False
            st.rerun()

    # M·ªõi th√™m: Ki·ªÉm tra v√† ƒë·∫£m b·∫£o t·∫•t c·∫£ tin nh·∫Øn ƒë·ªÅu c√≥ ngu·ªìn (ƒë·ªÉ l∆∞u ƒë√∫ng khi save_chat_history)
    for i, msg in enumerate(st.session_state.messages):
        if msg["role"] == "assistant" and ("sources" not in msg or not msg["sources"]):
            print(f"[app] Fix missing sources in message #{i}")
            # Tin nh·∫Øn assistant kh√¥ng c√≥ ngu·ªìn, th√™m ngu·ªìn m·∫∑c ƒë·ªãnh
            msg["sources"] = [{
                "source": "H·ªá th·ªëng",
                "chunk_id": "auto-fixed",
                "content": "Kh√¥ng c√≥ ngu·ªìn tham kh·∫£o c·ª• th·ªÉ. ƒê√£ t·ª± ƒë·ªông th√™m."
            }]

else:
    st.error("Tr·∫°ng th√°i kh√¥ng x√°c ƒë·ªãnh. ƒêang reset v·ªÅ trang ch·ªß.")
    reset_to_upload()
    st.rerun()